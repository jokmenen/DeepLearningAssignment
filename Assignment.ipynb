{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "1. Create Pandas DF with {Index, img, svg}\n",
    "2. Preprocess svg:\n",
    "    1. Split into 'words\n",
    "    2. add start and end sequence \n",
    "    3. Tokenize svg items\n",
    "    4. Calculate maximum length of svg files (in words\n",
    "    5. Create Sequences for the svg files\n",
    "3. Create and Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "from PIL import Image\n",
    "\n",
    "#Keras \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, Dropout,\\\n",
    "                        Conv2D, MaxPooling2D, Flatten, GRU\n",
    "from keras.layers.merge import add\n",
    "from keras.utils import plot_model\n",
    "from keras.backend import clear_session\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from charactertable import CharacterTable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DF\n",
    "def createDataFrame(index_range):\n",
    "    d = {'index' : [], 'img' : [], 'svg' : []}\n",
    "    for index in index_range:\n",
    "        img = np.array(Image.open(f'train/png/png/{index}.png'))[:,:,:3] # TODO Check alpha dimension\n",
    "        #svg = open(f'train/svg/{index}.svg').read()\n",
    "        svg = open(f'train/svg/{index}.svg').read()\n",
    "        \n",
    "        d['index'] += [index]\n",
    "        d['img'] += [img]\n",
    "        d['svg'] += [svg]\n",
    "    df = pandas.DataFrame(data=d)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_svg(svg_col):\n",
    "    # Split into words\n",
    "    new_col = [doc.split() for doc in svg_col]\n",
    "    \n",
    "    # Add start and end sequence\n",
    "    # Complile a set of all unique svg elements from all the SVG files\n",
    "    vocab = set() # set to prevent double elements\n",
    "    for doc in new_col:\n",
    "        doc.insert(0,'<start>')\n",
    "        doc.append('<end>')\n",
    "        vocab.update(doc)\n",
    "    \n",
    "    # Calculate maximum length of svg files in words\n",
    "    max_len = len(max(new_col, key=len))\n",
    "    \n",
    "\n",
    "    return new_col, vocab, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 10000 #Rerun all code if changing this\n",
    "df = createDataFrame(range(num_examples))\n",
    "df['svg'], vocab, max_len = preprocess_svg(df['svg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "Training Data:\n",
      "(8000, 64, 64, 3)\n",
      "(8000, 63, 60)\n",
      "(8000, 63, 60)\n",
      "Validation Data:\n",
      "(1000, 64, 64, 3)\n",
      "(1000, 63, 60)\n",
      "(1000, 63, 60)\n",
      "Test Data:\n",
      "(1000, 64, 64, 3)\n",
      "(1000, 63, 60)\n",
      "(1000, 63, 60)\n"
     ]
    }
   ],
   "source": [
    "chars = vocab\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "x1 = np.stack(df['img'])\n",
    "x2 = np.zeros((num_examples, max_len, ctable.num_tokens))\n",
    "y = np.zeros((num_examples, max_len, ctable.num_tokens))\n",
    "\n",
    "for i, sentence in enumerate(df['svg']):\n",
    "    x2[i] = ctable.encode(sentence[1:-1], max_len)\n",
    "\n",
    "for i, sentence in enumerate(df['svg']):\n",
    "    y[i] = ctable.encode(sentence, max_len)    \n",
    "\n",
    "# Explicitly set apart 10% for validation and test data.\n",
    "num_examples_val = len(x1) // 10\n",
    "print(num_examples_val)\n",
    "split_at_val = len(x1) - num_examples_val * 2\n",
    "split_at_test = len(x1) - num_examples_val\n",
    "x1_train = x1[:split_at_val]\n",
    "x2_train = x2[:split_at_val]\n",
    "y_train = y[:split_at_val]\n",
    "x1_val = x1[split_at_val:split_at_test]\n",
    "x2_val = x2[split_at_val:split_at_test]\n",
    "y_val = y[split_at_val:split_at_test]\n",
    "x1_test = x1[split_at_test:]\n",
    "x2_test = x2[split_at_test:]\n",
    "y_test = y[split_at_test:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(x1_train.shape)\n",
    "print(x2_train.shape)\n",
    "print(y_train.shape)\n",
    "print('Validation Data:')\n",
    "print(x1_val.shape)\n",
    "print(x2_val.shape)\n",
    "print(y_val.shape)\n",
    "print('Test Data:')\n",
    "print(x1_test.shape)\n",
    "print(x2_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 16)   448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 16)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 8)    1160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 8)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 16, 8)    584         max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 63, 60)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 8)      0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, None, 60)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     [(None, 512), (None, 880128      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     [(None, None, 512),  880128      input_3[0][0]                    \n",
      "                                                                 gru_1[0][1]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, 512)    0           flatten_1[0][0]                  \n",
      "                                                                 gru_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 60)     30780       add_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 1,793,228\n",
      "Trainable params: 1,793,228\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Fix for strange errors during training\n",
    "clear_session() #clear any previous keras sessions\n",
    "graph = tf.get_default_graph()\n",
    "##\n",
    "\n",
    "# Parameters for the model.\n",
    "hidden_size = 512\n",
    "\n",
    "#Image:\n",
    "input_img = Input(shape=(64, 64, 3))   \n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "encoded_img = Flatten()(x)\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(max_len, ctable.num_tokens))\n",
    "encoder_rnn_layer = GRU(hidden_size, return_state=True)\n",
    "# We discard the output of the layer and only keep the states.\n",
    "_, encoder_state = encoder_rnn_layer(encoder_inputs)\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, ctable.num_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_rnn_layer = GRU(hidden_size, return_sequences=True, return_state=True)\n",
    "\n",
    "decoder_outputs, _ = decoder_rnn_layer(decoder_inputs,\n",
    "                                       initial_state=encoder_state)\n",
    "\n",
    "decoder_add = add([encoded_img, decoder_outputs])\n",
    "decoder_dense = Dense(ctable.num_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_add)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_inputs` & `decoder_inputs` into `decoder_outputs`\n",
    "model = Model([input_img, encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "model.summary()\n",
    "#plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 70s 9ms/step - loss: 0.9126 - acc: 0.7744 - val_loss: 0.3807 - val_acc: 0.8388\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 68s 9ms/step - loss: 0.3675 - acc: 0.8471 - val_loss: 0.3662 - val_acc: 0.8485\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 69s 9ms/step - loss: 0.3504 - acc: 0.8581 - val_loss: 0.3523 - val_acc: 0.8586\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 69s 9ms/step - loss: 0.3337 - acc: 0.8684 - val_loss: 0.3377 - val_acc: 0.8687\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 68s 9ms/step - loss: 0.3187 - acc: 0.8764 - val_loss: 0.3272 - val_acc: 0.8747\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 68s 9ms/step - loss: 0.3091 - acc: 0.8815 - val_loss: 0.3214 - val_acc: 0.8766\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 69s 9ms/step - loss: 0.3026 - acc: 0.8848 - val_loss: 0.3202 - val_acc: 0.8777\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 69s 9ms/step - loss: 0.2974 - acc: 0.8870 - val_loss: 0.3139 - val_acc: 0.8813\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 69s 9ms/step - loss: 0.2925 - acc: 0.8895 - val_loss: 0.3137 - val_acc: 0.8811\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 69s 9ms/step - loss: 0.2881 - acc: 0.8912 - val_loss: 0.3124 - val_acc: 0.8827\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "history = model.fit([x1_train, x2_train, y_train[:, :-1]], y_train[:, 1:],\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    validation_data=([x1_val, x2_val, y_val[:, :-1]], y_val[:, 1:]),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_state)\n",
    "\n",
    "### PUT YOUR CODE HERE ###\n",
    "decoder_state_input = Input(shape=(hidden_size,))\n",
    "decoder_outputs, decoder_state = decoder_rnn_layer(\n",
    "    decoder_inputs, initial_state=decoder_state_input)\n",
    "decoder_add = add([encoded_img, decoder_outputs])\n",
    "decoder_outputs = decoder_dense(decoder_add)\n",
    "### END ###\n",
    "\n",
    "\n",
    "decoder_model = Model(\n",
    "    [input_img, decoder_inputs, decoder_state_input],\n",
    "    [decoder_outputs, decoder_state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UPDATE CODE HERE ###\n",
    "def decode_sequence(input_seq,img, max_decoder_seq_length):\n",
    "    # Encode the input as state vectors.\n",
    "    state_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, ctable.num_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, ctable.char_indices['<start>']] = 1.\n",
    "    \n",
    "    \n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_svg = []\n",
    "    while not stop_condition:\n",
    "        output_tokens, state_value = decoder_model.predict(\n",
    "            [img, target_seq, state_value])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = ctable.indices_char[sampled_token_index]\n",
    "        decoded_svg += [sampled_char]\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '<end>' or\n",
    "           len(decoded_svg) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, ctable.num_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "    return decoded_svg\n",
    "### END ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'\n",
    "    \n",
    "# Select 10 samples from the validation set at random so we can visualize\n",
    "# errors.\n",
    "\n",
    "save_dir = 'genSVG\\\\'\n",
    "for i in range(10):\n",
    "    ind = np.random.randint(0, len(x2_test))\n",
    "    img, q, ea = x1_test[np.array([ind])], x2_test[np.array([ind])], y_test[np.array([ind])]\n",
    "    pred = ' '.join(decode_sequence(q, img, max_len)[:-1])\n",
    "    q = ctable.decode(q[0])\n",
    "#     correct = ''.join([ctable.indices_char[x] for x in ea[0] if x != 0])\n",
    "    answer = ea[0].tolist()\n",
    "    \n",
    "    correct = ' '.join([ctable.indices_char[np.argmax(x)] for x in answer if np.argmax(x) != 0][1:-1])\n",
    "#     print('Q', q[::-1]) # if reverse else q, end=' '\n",
    "#     print()\n",
    "#     print('T', correct, end=' ')\n",
    "#     print()\n",
    "#     if correct == pred:\n",
    "#         print(colors.ok + '☑' + colors.close, end=' ')\n",
    "#     else:\n",
    "#         print(colors.fail + '☒' + colors.close, end=' ')\n",
    "    with open(f'{save_dir}{i}-pred.svg','w') as fp:\n",
    "        fp.write(pred)\n",
    "    with open(f'{save_dir}{i}-corr.svg','w') as fp:\n",
    "        fp.write(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
